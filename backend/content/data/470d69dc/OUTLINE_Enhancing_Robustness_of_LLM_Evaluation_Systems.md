1. Introduction: The importance of robust LLM evaluation systems in AI and machine learning.
2. Adversarial Training Techniques: Overview of methods to enhance evaluation robustness.
3. Synthetic Negative Samples: Construction by truncating model outputs to first sentences and their role in training.
4. Benefits of Synthetic Negative Samples: Reduction of susceptibility to superficial prompt manipulations.
5. Empirical Results: Improvements observed on benchmarks like GSM8K, MATH, and AIME datasets.
6. Vulnerabilities in Current Evaluators: Issues such as response ordering, adversarial phrases, and nonsensical strings.
7. Master-RM Model: Training for robustness and achieving near-zero false positive rates against adversarial attacks.
8. Implications for High-Stakes Applications: Necessity of reliable, trustworthy, and resilient evaluators.
9. Future Directions: Continued adversarial data augmentation and specialized training methods for LLM evaluators.
10. Conclusion: Summary of advances in making LLM evaluation systems more robust and trustworthy.
